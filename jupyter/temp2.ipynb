{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5505f90e-36fb-4c7e-a2b5-a7e638f8fbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import wave\n",
    "import random\n",
    "import numpy as np\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import PIL\n",
    "\n",
    "\n",
    "sys.path.append('../training')\n",
    "from utils import data_utils, utils, audio_utils\n",
    "from datasets.loader import Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4074434d-9d90-4468-9982-6761b91f4180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_dir = '/home/jaejun/nansy/\n",
    "config_path = '../training/configs/f2v.json'\n",
    "with open(config_path, \"r\") as f:\n",
    "    data = f.read()\n",
    "config = json.loads(data)\n",
    "args = utils.HParams(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4dde7f4-07ad-48b7-93db-49dc431b5726",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TMP_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,\n",
    "                args,\n",
    "                meta_root = 'filelists',\n",
    "                mode='train',\n",
    "                img_datasets=['VGG_Face'],\n",
    "                sample_rate = 16000, \n",
    "                ):\n",
    "        self.args = args\n",
    "        self.mode = mode\n",
    "        self.img_datasets = img_datasets\n",
    "        self.sample_rate = sample_rate\n",
    "        self.max_sec = 4\n",
    "        self.max_len = sample_rate * self.max_sec\n",
    "        self.data_files = []\n",
    "        for dset in img_datasets:\n",
    "            meta_file_path = os.path.join(meta_root, '{}_{}.txt').format(dset, mode)\n",
    "            files = data_utils.load_text(meta_file_path)\n",
    "            self.data_files += files\n",
    "        self.data_files_len = len(self.data_files)\n",
    "        self.trans = transforms.Compose([transforms.Resize((args.features.image.size,args.features.image.size), interpolation=PIL.Image.BICUBIC),\n",
    "                transforms.CenterCrop(args.features.image.size), transforms.ToTensor()])\n",
    "        \n",
    "    def get_image(self, index):\n",
    "        img = Image.open()\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.data_files[index]\n",
    "        img = Image.open(img_path)\n",
    "        img_tensor = self.trans(img)\n",
    "        return img_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab6a6cbb-8534-485b-a8d0-f2df2bbbf39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpset = TMP_Dataset(args, img_datasets=[\"VGG_Face\"], meta_root='../training/filelists/VGG_Face')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c59a2dc2-e1bc-402e-8f31-bdddaf0bc747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stdv(dataset):\n",
    "    # dataset의 axis=1, 2에 대한 평균 산출\n",
    "    std_ = np.array([np.std(x.numpy(), axis=(1, 2)) for x in dataset])\n",
    "    # r, g, b 채널에 대한 각각의 표준편차 산출\n",
    "    std_r = std_[:, 0].mean()\n",
    "    std_g = std_[:, 1].mean()\n",
    "    std_b = std_[:, 2].mean()\n",
    "\n",
    "    return (std_r, std_g, std_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "feda7d25-9bb8-46b7-bb3b-b52582e85487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.26429313, 0.23981343, 0.23351036)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_stdv(tmpset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea0c9f6-d27e-4750-b662-8a2f16fe0cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f19a06b-fcd3-4906-bf2e-4dfbb1b90c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f47d548-0073-46c4-a573-f1750d6cb33d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
